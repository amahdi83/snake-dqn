# ğŸ Snake Game with Deep Q-Learning ğŸ§ 


![Trained Snake Example](example.gif)


Welcome to the **Snake Game AI Project**! This project is a modern twist on the classic Snake game, featuring a custom Pygame implementation and an AI agent trained using **Deep Q-Learning (DQN)**. The agent learns to play Snake through trial and error â€” and yes, it's fun to watch! ğŸ˜„

---

## ğŸ® Game Overview
The Snake game is rendered with a grid-style UI using `pygame`, complete with score tracking and levels. The AI learns to play by observing the game state and taking actions like:

- `0` â¡ï¸ Continue straight
- `1` â†©ï¸ Turn left
- `2` â†ªï¸ Turn right

The game environment provides feedback (rewards) based on survival, collisions, and eating food.

---

## ğŸ“‚ Modes
Choose from one of three gameplay modes in `train_snake.py`:

### 1. `"play"` ğŸ‘¾ Manual Mode
Play the game yourself using the arrow keys!
```python
mode = "play"
```

### 2. `"train"` ğŸ¤– AI Training Mode
Train the AI agent using Deep Q-Learning.
```python
mode = "train"
```

### 3. `"test"` ğŸ§ª Watch the Trained Agent
Train the AI agent using Deep Q-Learning.
```python
mode = "test"
```

---

## ğŸ› ï¸ How To
### âœ… Requirements
Make sure you have Python 3.7+ and install the required dependencies:
```python
pip install -r requirements.txt
```
requirements.txt:
```python
numpy
torch
pygame
```

## ğŸš€ Run the Game
#### 1. Train the Agent:
```python
python train_snake.py
```

#### 2. Watch the Trained Agent:
```python
# Make sure mode is set to "test" in train_snake.py
python train_snake.py
```

#### 3. Play Manually:
```python
# Set mode = "play"
python train_snake.py
```

---

## ğŸ“ AI Agent Overview
The agent uses a simple feed-forward neural network with the following input features:
```python
[danger_straight, danger_left, danger_right,
 food_dx, food_dy,
 dir_x, dir_y]
 ```
It gets rewarded for:
- ğŸ Eating food: +10
- âŒ Hitting walls or itself: -10
- ğŸ¢ Taking too long: -10

The agent uses experience replay and epsilon-greedy exploration to learn effective strategies over time.

---

## ğŸ“¸ Demo
Check out this animation of a trained snake navigating the grid like a champ! ğŸğŸ”¥

---

## ğŸ’¾ Saving & Loading
The agent model is saved to dqn_snake.pth after training.
You can load it back in test mode to watch it play.

---

## ğŸ§  Bonus: Train Smarter
Modify training parameters in DQNAgent like:
- epsilon_decay
- batch_size
- gamma (discount rate)

---

âœ¨ Future Ideas
- Add obstacles ğŸ§±
- Add multiple agents for competition ğŸ¥Š
- Use CNNs for vision-based state representation ğŸ‘ï¸

---

## ğŸ“¬ Contact
Made with â¤ï¸ by Ali Mahdi. Feel free to reach out with questions, suggestions, or cool ideas!
